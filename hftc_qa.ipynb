{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.154'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "import praw\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import openai\n",
    "\n",
    "import langchain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# load secrets from .env into environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- interrogate praw docs and write code to download from reddit\n",
    "- do some language stuff and extract the songs\n",
    "- interrogate spotipy write code to look up the uri\n",
    "- interrogate spotipy, write code to get the playlist id\n",
    "- interrogate spotipy, write code to update the playlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_obj = openai.Model.list()\n",
    "# sorted([m['id'] for m in models_obj['data']])\n",
    "\n",
    "# add pinecone\n",
    "# do the csv thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work for some reason, end up in version hell\n",
    "# loader = DirectoryLoader(hftcdir, glob=\"*.txt\")\n",
    "# d=loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hftcdir = '/Users/drucev/notebooks/llamaindex/gpt_index/examples/hftc'\n",
    "\n",
    "documents = None\n",
    "for f in glob.glob('%s/*' % hftcdir):\n",
    "\n",
    "#     print(f)\n",
    "    if documents is None:\n",
    "        documents = TextLoader(f).load()\n",
    "    else:\n",
    "        documents.extend(TextLoader(f).load())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 splitting 2023-05-02 13:38:44.493895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 getting embeddings 2023-05-02 13:38:45.904285\n",
      "4 instantiate retriever 2023-05-02 13:43:43.606870\n"
     ]
    }
   ],
   "source": [
    "embedding_model = 'text-embedding-ada-002'   # default\n",
    "\n",
    "# split the documents into chunks\n",
    "print(1, 'splitting', datetime.now())\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "# load embeddings into vector db\n",
    "print(2, 'getting embeddings', datetime.now())\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model,\n",
    "                              deployment = embedding_model,\n",
    ")\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "print(4, 'instantiate retriever', datetime.now())\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "llm = ChatOpenAI(model_name=qa_model, \n",
    "                 temperature=0.2,\n",
    "                )\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 return_source_documents=True\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain to answer questions\n",
    "# print(5, datetime.now())\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(model_name=qa_model, \n",
    "#                                             temperature=0.5), \n",
    "#                                  chain_type=\"stuff\", \n",
    "#                                  retriever=retriever, \n",
    "#                                  return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email doesn't mention all the names of endpoint protection products, but it does mention two: Sophos and Symantec.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the names of some endpoint protection products?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email mentions three MSPs: AlphaServe, CDI, and Agio. However, it does not provide any opinions or recommendations about them.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the names of some good Managed Service Providers or MSPs?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are many Managed Security Service Providers (MSSPs) and Managed Detection and Response (MDR) companies in the market. Some of the well-known MSSPs and MDRs are IBM Security, SecureWorks, Trustwave, Alert Logic, Arctic Wolf, CrowdStrike, FireEye, and Palo Alto Networks. However, it's important to note that the best MSSP or MDR for your company will depend on your specific security needs and budget.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the names of Managed Security Service Providers or MDRs or MSSPs?\"\n",
    "result = qa({\"query\": query})\n",
    "result['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
