{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.154'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "import praw\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import openai\n",
    "\n",
    "import langchain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# load secrets from .env into environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- interrogate praw docs and write code to download from reddit\n",
    "- do some language stuff and extract the songs\n",
    "- interrogate spotipy write code to look up the uri\n",
    "- interrogate spotipy, write code to get the playlist id\n",
    "- interrogate spotipy, write code to update the playlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_obj = openai.Model.list()\n",
    "# sorted([m['id'] for m in models_obj['data']])\n",
    "\n",
    "# add pinecone\n",
    "# do the csv thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work for some reason, end up in version hell\n",
    "# loader = DirectoryLoader(hftcdir, glob=\"*.txt\")\n",
    "# d=loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hftcdir = '/Users/drucev/notebooks/llamaindex/gpt_index/examples/hftc'\n",
    "\n",
    "documents = None\n",
    "for f in glob.glob('%s/*' % hftcdir):\n",
    "\n",
    "#     print(f)\n",
    "    if documents is None:\n",
    "        documents = TextLoader(f).load()\n",
    "    else:\n",
    "        documents.extend(TextLoader(f).load())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 splitting 2023-05-02 13:38:44.493895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 getting embeddings 2023-05-02 13:38:45.904285\n",
      "4 instantiate retriever 2023-05-02 13:43:43.606870\n"
     ]
    }
   ],
   "source": [
    "embedding_model = 'text-embedding-ada-002'   # default\n",
    "\n",
    "# split the documents into chunks\n",
    "print(1, 'splitting', datetime.now())\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "# load embeddings into vector db\n",
    "print(2, 'getting embeddings', datetime.now())\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model,\n",
    "                              deployment = embedding_model,\n",
    ")\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "print(4, 'instantiate retriever', datetime.now())\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = 'gpt-3.5-turbo-0301'\n",
    "\n",
    "llm = ChatOpenAI(model_name=qa_model, \n",
    "                 temperature=0.2,\n",
    "                )\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 return_source_documents=True\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain to answer questions\n",
    "# print(5, datetime.now())\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(model_name=qa_model, \n",
    "#                                             temperature=0.5), \n",
    "#                                  chain_type=\"stuff\", \n",
    "#                                  retriever=retriever, \n",
    "#                                  return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email doesn't provide a comprehensive list of leading endpoint protection products, but it does mention two: Sophos (the current vendor) and Symantec (used at the author's previous job). Other popular endpoint protection products include McAfee, Kaspersky, Trend Micro, and Bitdefender. It's important to do research and evaluate different products to determine which one best fits your specific needs.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are some leading endpoint protection products?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email mentions three Managed Service Providers: AlphaServe, CDI, and Agio. However, it does not provide any opinions or recommendations about them.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the names of some good Managed Service Providers?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are several leading Managed Security Service Providers (MSSPs) and Managed Detection and Response (MDR) companies in the market. Some of the top MSSPs include IBM Security, SecureWorks, AT&T Cybersecurity, Verizon, and Trustwave. Some of the top MDR companies include CrowdStrike, FireEye, Cybereason, Carbon Black, and Palo Alto Networks. However, it's important to note that the best provider for your company will depend on your specific needs and requirements.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the names of leading Manged Security Service Providers or MDRs or MSSPs?\"\n",
    "result = qa({\"query\": query})\n",
    "result['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
