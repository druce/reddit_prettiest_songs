{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "import praw\n",
    "\n",
    "import openai\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# load secrets from .env into environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "praw.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo, make proper readme, \n",
    " - objective is to use OpenAI for named entity extraction to extract all the songs form [this reddit thread](https://www.reddit.com/r/AskReddit/comments/12viv4v/what_is_the_prettiest_song_you_ever_heard_in_your/) and make Spotify playlist\n",
    " - use Reddit PRAW API to download all the comments (get [Reddit API key](https://www.reddit.com/prefs/apps))\n",
    " - use OpenAI API with a prompt like, extract all the songs from this text to CSV get ([OpenAI API key](https://platform.openai.com/account/api-keys))\n",
    " - use Spotify API to make a playlist (get [Spotify API key](https://developer.spotify.com/documentation/web-api/tutorials/getting-started))\n",
    " - works, needed a lot of scrubbing, but about 1 day of work, wouldn't have been possible to do a 700-song playlist manually without a team of Mechanical Turks or something\n",
    " - If I wanted to go nuts, would process comments individually, save a file for each comment's extracted songs, would make it easier to track down what OpenAI gets wrong, have a resumable, retryable, repeatable process and \n",
    " - output a big github table of all the songs in the readme and link to spotify playlist and individual songs\n",
    " \n",
    " needs a .env file per dot-env-template\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all comments from a reddit posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPraw():\n",
    "    return praw.Reddit(user_agent=\"prettiest_song/0.001\", \n",
    "                       client_id=os.getenv('CLIENT_ID'), \n",
    "                       client_secret=os.getenv('CLIENT_SECRET'))\n",
    "\n",
    "\n",
    "def getAll(r, submissionId, verbose=True):\n",
    "    submission = r.submission(submissionId)\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    commentsList=submission.comments.list()\n",
    "    return commentsList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 22:03:09.201043\n"
     ]
    }
   ],
   "source": [
    "submission = \"12viv4v\"\n",
    "print(datetime.now())\n",
    "r = getPraw()\n",
    "res = getAll(r, submission)\n",
    "print(datetime.now())\n",
    "\n",
    "print(\"retrieved \", len(res), 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a list of comment objects\n",
    "# filter comments with at least 5 karma\n",
    "res3 = [r for r in res if r.score >= 5]\n",
    "res3[0].body, res3[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all songs using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each comment object we will extract the body \n",
    "# then submit as part of a prompt to chatgpt\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "pd.DataFrame(openai.Model.list()[\"data\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = res3.copy()\n",
    "outfile = open('bronze.txt', 'w')\n",
    "\n",
    "while(slist):\n",
    "    prompt = \"\"\"Define an example CSV file output as follows: \n",
    "\"artist\",\"song_title\"\n",
    "\"The Beatles\",\"Yesterday\"\n",
    "\"Eagles\",\"Hotel California\"\n",
    "\n",
    "from the following text, extract all song titles and artists, and return a CSV file output of extracted artists and song titles exactly as defined above:\n",
    "        \n",
    "\"\"\"\n",
    "    for _ in range(20):  # add up to 20 posts to the prompt\n",
    "        if slist and len(prompt) < 4096:  # max tokens is 4096 but we'll limit each prompt to 4096 chars\n",
    "            prompt += slist.pop(0).body\n",
    "            \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo-0301',\n",
    "        messages=[{\"role\":\"user\", \n",
    "                   \"content\": prompt}])\n",
    "\n",
    "    outfile.write(response['choices'][0]['message']['content'])\n",
    "    outfile.write('\\n\\n')\n",
    "    outfile.flush()\n",
    "    print('.', end='')\n",
    "\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will have to tweak the file to get it to load\n",
    "\n",
    "df = pd.read_csv(\"bronze.txt\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates() \\\n",
    "    .dropna() \\\n",
    "    .sort_values([\"artist\", \"song_tittle\"]) \\\n",
    "    .to_csv('silver.csv', index=False)\n",
    "\n",
    "# tweak further to get to gold.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into a Spotify playlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=os.getenv('SPOTIFY_CLIENT_ID'), \n",
    "                                                      client_secret=os.getenv('SPOTIFY_CLIENT_SECRET'),\n",
    "                                                      )\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get playlist ids\n",
    "# first create a playlist in UI to load songs\n",
    "playlists = sp.user_playlists(os.getenv('SPOTIFY_USERNAME'))\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        if playlist['name'] != 'reddit':\n",
    "            continue\n",
    "        print(playlist['id'])\n",
    "        print(\"%4d %s %s\" % (i + 1 + playlists['offset'], playlist['uri'],  playlist['name']))\n",
    "    if playlists['next']:\n",
    "        playlists = sp.next(playlists)\n",
    "    else:\n",
    "        playlists = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gold.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe = {}\n",
    "mylist = []\n",
    "fail_list = []\n",
    "for index, artist, title in df.itertuples():\n",
    "    query_str = 'artist:%s track:%s' % (artist, title)\n",
    "    track_results = sp.search(q=query_str, type='track', limit=10, offset=0, market='US')\n",
    "    results = track_results['tracks']['items']\n",
    "    # sort by popularity\n",
    "    if results:\n",
    "        results.sort(key=lambda z: z['popularity'], reverse=True)    \n",
    "        r = results[0]\n",
    "        # failsafe to never put same track twice\n",
    "        if dedupe.get(r['id']):\n",
    "            continue\n",
    "        dedupe[r['id']]=True\n",
    "        mylist.append(r['uri'])\n",
    "        print(artist, '--', title)\n",
    "        print('  ',\n",
    "              r['artists'][0]['name'],'|',\n",
    "              r['name'], '|',\n",
    "              r['album']['name'],'|',\n",
    "              r['album']['release_date'],'|',\n",
    "              r['popularity'])\n",
    "    else:\n",
    "        fail_list.append((artist, title))\n",
    "        print(\"not found:\", artist, \"-\", title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must follow an oauth workflow to write a playlist in Spotify\n",
    "# running this cell should request a spotify login and then redirect to an url\n",
    "# paste whole url with id into form to authenticate\n",
    "\n",
    "scope = \"playlist-modify-public\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=spotipy.SpotifyOAuth(scope=scope,\n",
    "                                                       client_id=os.getenv('SPOTIFY_CLIENT_ID'),\n",
    "                                                       client_secret=os.getenv('SPOTIFY_CLIENT_SECRET'),\n",
    "                                                       redirect_uri=\"https://druce.ai\"\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addlist = mylist.copy()\n",
    "print (len(addlist))\n",
    "\n",
    "while(addlist):\n",
    "    sp.user_playlist_add_tracks(os.getenv('SPOTIFY_USERNAME'), \n",
    "                                playlist_id='5TCTR1JE09PNJU79kiZgHZ', \n",
    "                                tracks=addlist[-100:])\n",
    "    addlist = addlist[:-100]\n",
    "    print(\"added items, remaining \", len(addlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add the ones that weren't found for some reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
