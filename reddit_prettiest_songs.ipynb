{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "import praw\n",
    "\n",
    "import openai\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# load secrets from .env into environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "praw.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See README.md\n",
    " - objective is to use OpenAI for named entity extraction to extract all the songs form [this reddit thread](https://www.reddit.com/r/AskReddit/comments/12viv4v/what_is_the_prettiest_song_you_ever_heard_in_your/) and make Spotify playlist\n",
    " - use Reddit PRAW API to download all the comments (get [Reddit API key](https://www.reddit.com/prefs/apps))\n",
    " - use OpenAI API with a prompt like, extract all the songs from this text to CSV get ([OpenAI API key](https://platform.openai.com/account/api-keys))\n",
    " - use Spotify API to make a playlist (get [Spotify API key](https://developer.spotify.com/documentation/web-api/tutorials/getting-started))\n",
    " - works, needed a lot of scrubbing, but about 1 day of work, wouldn't have been possible to do a 700-song playlist manually without a team of Mechanical Turks or something\n",
    " - If I wanted to go nuts, would process comments individually, save a file for each comment's extracted songs, would make it easier to track down what OpenAI gets wrong, have a resumable, retryable, repeatable process and \n",
    " - Spotify playist is [here](https://open.spotify.com/playlist/08YFkbtTV6GBfNtjJ4PHDu?si=f4761d983ac84091) \n",
    " \n",
    " needs a .env file per dot-env-template\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a thread \n",
    "submission = \"12viv4v\"\n",
    "\n",
    "# minimum karma to process a reply \n",
    "minkarma = 5\n",
    "\n",
    "# a prompt to apply to replies on the thread\n",
    "# prefix = \"\"\"Define an example CSV file output as follows: \n",
    "# \"artist\",\"song_title\"\n",
    "# \"The Beatles\",\"Yesterday\"\n",
    "# \"Eagles\",\"Hotel California\"\n",
    "\n",
    "# Extract all song titles and artists from the following input, and return a CSV file output of the artists and song titles you extract from the input. If there were no songs extracted from the input, return \"no songs found\". the input is:\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# an output file to accumulate all the responses\n",
    "savefile = 'bronze.txt'\n",
    "\n",
    "system_prompt=\"You will act as a research assistant finding all the artists and track titles in a document.\"\n",
    "assistant_prompt=\"\"\"Define a comma-separated values output as follows: \n",
    "artist,track\n",
    "\"The Beatles\",\"Yesterday\"\n",
    "\"Eagles\",\"Hotel California\" \"\"\"\n",
    "user_prefix=\"\"\"You will extract all artists and tracks from the following input, and return a list of records containing each artist and track extracted from the input in a comma-separated values format. The header row should contain `\"artist\", \"track\"`. The fields in each record should be enclosed in double-quotes. The input is:\"\"\"\n",
    "# an output file to accumulate all the responses\n",
    "savefile = 'bronze.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_validate_re = re.compile(r'''\n",
    "    \\s*                # Any whitespace.\n",
    "    (                  # Start capturing here.\n",
    "      [^,\"']+?         # Either a series of non-comma non-quote characters.\n",
    "      |                # OR\n",
    "      \"(?:             # A double-quote followed by a string of characters...\n",
    "          [^\"\\\\]|\\\\.   # That are either non-quotes or escaped...\n",
    "       )*              # ...repeated any number of times.\n",
    "      \"                # Followed by a closing double-quote.\n",
    "      |                # OR\n",
    "      '(?:[^'\\\\]|\\\\.)*'# Same as above, for single quotes.\n",
    "    )                  # Done capturing.\n",
    "    \\s*                # Allow arbitrary space before the comma.\n",
    "    (?:,|$)            # Followed by a comma or the end of a string.\n",
    "    ''', re.VERBOSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all comments from a reddit posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPraw():\n",
    "    return praw.Reddit(user_agent=\"prettiest_song/0.001\", \n",
    "                       client_id=os.getenv('CLIENT_ID'), \n",
    "                       client_secret=os.getenv('CLIENT_SECRET'))\n",
    "\n",
    "\n",
    "def getAll(r, submissionId, verbose=True):\n",
    "    submission = r.submission(submissionId)\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    commentsList=submission.comments.list()\n",
    "    return commentsList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datetime.now())\n",
    "# r = getPraw()\n",
    "# res = getAll(r, submission)\n",
    "# print(datetime.now())\n",
    "\n",
    "# print(\"retrieved \", len(res), 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we have a list of comment objects\n",
    "# # filter comments with at least some karma\n",
    "# res3 = [r for r in res if r.score >= minkarma]\n",
    "# print('filtered to ', len(res3), 'comments')\n",
    "# res3[0].body, res3[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save so we can reload it later without downloading\n",
    "\n",
    "# with open('reddit.pkl', 'wb') as f:\n",
    "#     pickle.dump(res3, f)\n",
    "    \n",
    "with open('reddit.pkl', 'rb') as f:\n",
    "    res3 = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract artists and song titles using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474 4162\n",
      "1539 W\n"
     ]
    }
   ],
   "source": [
    "# check lengths of posts\n",
    "shorties = []\n",
    "big_ones = []\n",
    "for i in range(len(res3)):\n",
    "    if len(res3[i].body) <3:\n",
    "        print (i, res3[i].body)\n",
    "        shorties.append(i)\n",
    "    if len(res3[i].body) > 4096:\n",
    "        print(i, len(res3[i].body))\n",
    "        big_ones.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.34075546719681"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg length\n",
    "sum([len(r.body) for r in res3]) / len(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturn by Sleeping at Last:\n",
      "https://www.youtube.com/watch?v=dzNvk80XY9s\n",
      "\n",
      "The version they did with Tim Fain is even more beautiful: \n",
      "https://www.youtube.com/watch?v=0nRpeAiur9Q\n",
      "\n",
      "I'm not good at choosing one thing from a list of favorites as the best, so I've got about 30+ answers that are really a 30+ -way tie, and the one that I would consider as \"prettiest\" at any given moment is heavily influenced by my current mood. So, it could be any one of these from my \"Heart Wrenchingly Beautiful\" playl\n"
     ]
    }
   ],
   "source": [
    "print (res3[big_ones[0]].body[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:51:58.674650\n",
      "processing 2515 posts\n",
      "80 163 232 318 385 447 511 557 610 656 698 747 788 833 884 921 980 1038 1090 1148 1200 1252 1310 1367 1430 1479 1540 1591 1645 1686 1726 1780 1815 1866 1914 1960 2011 2051 2103 2157 2203 2240 2278 2313 2356 2394 2441 2481 2515 \n",
      "2023-05-04 15:11:39.987012\n"
     ]
    }
   ],
   "source": [
    "# for each comment object we will extract the body \n",
    "# then submit as part of a prompt to chatgpt\n",
    "print(datetime.now())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "slist = res3.copy()\n",
    "total_posts = len(slist)\n",
    "print(\"processing %d posts\" % total_posts)\n",
    "\n",
    "# to speed things we'll cumulate posts til we get to 100 posts or 5000 chars, whichever comes first\n",
    "max_post_size=300  # redditor needs to put any songs in 1st couple hundred chars, c'mon\n",
    "maxchars = 5000  # max tokens is 4096 but we'll limit each prompt to 5000 chars\n",
    "nposts = 100 # max posts to combine into a chunk\n",
    "\n",
    "# make sure no single post > maxchars + prefix which breaks the logic below\n",
    "for i in range(len(slist)):\n",
    "    if len(slist[i].body) > maxchars + len(user_prefix):\n",
    "        print (\"truncated \", i)\n",
    "        slist[i].body = slist[i].body[:maxchars + len(user_prefix)]\n",
    "        \n",
    "outdir = 'out'\n",
    "logdir = 'logs'\n",
    "# make sure out and logs are empty\n",
    "for f in glob.glob('%s/*' % outdir):\n",
    "    os.remove(f)\n",
    "for f in glob.glob('%s/*' % logdir):\n",
    "    os.remove(f)\n",
    "count = 0\n",
    "c = 0\n",
    "\n",
    "while(slist):  # still comments to process\n",
    "    prompt = \"\"\n",
    "    reply_ids = []\n",
    "\n",
    "    for _ in range(nposts):  # add up to 100 posts to the prompt\n",
    "        if slist:\n",
    "            # make sure no single post > max_post_size, truncate as nec \n",
    "            slist[0].body = slist[0].body[:max_post_size]\n",
    "            if len(prompt) + len(slist[0].body) < maxchars:\n",
    "                reply = slist.pop(0)\n",
    "                reply_ids.append(reply.id)\n",
    "                body = reply.body\n",
    "                prompt += body\n",
    "                prompt += \" \\n \\n\"\n",
    "                c += 1            \n",
    "            \n",
    "    # retry loop, have received untrapped 502 error\n",
    "    response=''\n",
    "    RETRIES = 3\n",
    "    success = False    \n",
    "    for i in range(RETRIES):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo-0301',\n",
    "                messages=[{\"role\":\"system\", \"content\": system_prompt},\n",
    "                          {\"role\":\"assistant\", \"content\": assistant_prompt},\n",
    "                          {\"role\":\"user\", \"content\": user_prefix + prompt}\n",
    "                         ],\n",
    "                temperature=0,\n",
    "            )\n",
    "            success=True\n",
    "        except Exception as error:\n",
    "            print(\"An exception occurred:\", error)\n",
    "            print(\"Retrying chunk...\")\n",
    "            time.sleep(5)\n",
    "            continue  # try again\n",
    "        # SUCCESS - exception not triggered\n",
    "        break   \n",
    "    if not success:   # FAIL - retries exhausted\n",
    "        print('Bailing to next chunk')\n",
    "        continue\n",
    "\n",
    "    # do basic validation and cleanup\n",
    "    csv_output = response['choices'][0]['message']['content']\n",
    "    csv_valid, csv_err = [], []\n",
    "    for line in csv_output.split(\"\\n\"):\n",
    "        try:\n",
    "            csv_values = csv_validate_re.findall(line)\n",
    "            if len(csv_values) == 2:\n",
    "                csv_valid.append(line)\n",
    "            else:\n",
    "                csv_err.append(line)\n",
    "        except:\n",
    "            csv_err.append(line)\n",
    "    csv_output = \"\\n\".join(csv_valid)\n",
    "        \n",
    "    with open(\"%s/%04d.csv\" % (outdir, count), 'w') as outfile:\n",
    "        outfile.write(csv_output)\n",
    "    \n",
    "    if csv_err:\n",
    "        with open(\"%s/%04d.err\" % (outdir, count), 'w') as outfile:\n",
    "            outfile.write(\"\\n\".join(csv_err))\n",
    "        \n",
    "    with open(\"%s/%04d.log\" % (logdir, count), 'w') as logfile:\n",
    "        logfile.write(str(reply_ids))\n",
    "        logfile.write('\\n\\n===== raw prompt =====\\n\\n')        \n",
    "        logfile.write(prompt)\n",
    "        logfile.write('\\n\\n===== raw response =====\\n\\n')\n",
    "        logfile.write(response['choices'][0]['message']['content'])\n",
    "        if csv_err:\n",
    "            logfile.write('\\n\\n===== failed validation =====\\n\\n')\n",
    "            logfile.write(\"\\n\".join(csv_err))\n",
    " \n",
    "    count += 1\n",
    "#     print(c)\n",
    "    print(total_posts-len(slist), end=' ')\n",
    "    \n",
    "print()\n",
    "print(datetime.now())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/0000.csv\n",
      "out/0001.csv\n",
      "out/0002.csv\n",
      "out/0003.csv\n",
      "out/0004.csv\n",
      "out/0005.csv\n",
      "out/0006.csv\n",
      "out/0007.csv\n",
      "out/0008.csv\n",
      "out/0009.csv\n",
      "out/0010.csv\n",
      "out/0011.csv\n",
      "out/0012.csv\n",
      "out/0013.csv\n",
      "out/0014.csv\n",
      "out/0015.csv\n",
      "out/0016.csv\n",
      "out/0017.csv\n",
      "out/0018.csv\n",
      "out/0019.csv\n",
      "out/0020.csv\n",
      "out/0021.csv\n",
      "out/0022.csv\n",
      "out/0023.csv\n",
      "out/0024.csv\n",
      "out/0025.csv\n",
      "out/0026.csv\n",
      "out/0027.csv\n",
      "out/0028.csv\n",
      "out/0029.csv\n",
      "out/0030.csv\n",
      "out/0031.csv\n",
      "out/0032.csv\n",
      "out/0033.csv\n",
      "out/0034.csv\n",
      "out/0035.csv\n",
      "out/0036.csv\n",
      "out/0037.csv\n",
      "out/0038.csv\n",
      "out/0039.csv\n",
      "out/0040.csv\n",
      "out/0041.csv\n",
      "out/0042.csv\n",
      "out/0043.csv\n",
      "out/0044.csv\n",
      "out/0045.csv\n",
      "out/0046.csv\n",
      "out/0047.csv\n",
      "out/0048.csv\n"
     ]
    }
   ],
   "source": [
    "# may still have to tweak the files to get them to load\n",
    "# should inspect .err files and clean up if possible\n",
    "\n",
    "filelist = glob.glob('%s/*.csv' % outdir)\n",
    "\n",
    "output_df = None\n",
    "\n",
    "for f in sorted(filelist):\n",
    "    print(f)\n",
    "    try:\n",
    "        tempdf = pd.read_csv(\"%s\" % (f), header=None)\n",
    "    except Exception as exc:\n",
    "        print(str(exc))\n",
    "        continue\n",
    "    colcount = len(tempdf.columns)\n",
    "    if len(tempdf.columns) != 2:\n",
    "        print('%s has %d columns, skipped' % (f, colcount))\n",
    "        continue\n",
    "    tempdf.columns=['artist', 'track']\n",
    "        \n",
    "    # ok\n",
    "    # truncate header row\n",
    "    if tempdf.iloc[0][0]=='artist' and tempdf.iloc[0][1]=='track':\n",
    "        tempdf = tempdf[1:]\n",
    "    if output_df is not None:        \n",
    "        output_df = pd.concat([output_df, tempdf], axis=0)\n",
    "    else:\n",
    "        output_df = tempdf\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erik Satie</td>\n",
       "      <td>Gymnopédies - Erik Satie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don McLean</td>\n",
       "      <td>Vincent (Starry, Starry Night)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lord Huron</td>\n",
       "      <td>The night we met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neil Young</td>\n",
       "      <td>Harvest Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simon &amp; Garfunkel</td>\n",
       "      <td>Scarborough Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>All Along the Watchtower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nightwish</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Elton John</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Claude Debussy</td>\n",
       "      <td>Clair de Lune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Glenn Miller</td>\n",
       "      <td>In The Mood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                           track\n",
       "1          Erik Satie        Gymnopédies - Erik Satie\n",
       "2          Don McLean  Vincent (Starry, Starry Night)\n",
       "3          Lord Huron                The night we met\n",
       "4          Neil Young                    Harvest Moon\n",
       "5   Simon & Garfunkel                Scarborough Fair\n",
       "..                ...                             ...\n",
       "12          Bob Dylan        All Along the Watchtower\n",
       "13          Nightwish                         unknown\n",
       "14         Elton John                         unknown\n",
       "15     Claude Debussy                   Clair de Lune\n",
       "16       Glenn Miller                     In The Mood\n",
       "\n",
       "[1588 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1588"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save bronze\n",
    "output_df.to_csv(savefile, index=False)\n",
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ludovico Einaudi</td>\n",
       "      <td>Divenire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ludovico Einaudi</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.Hack//SIGN</td>\n",
       "      <td>Key of the Twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>Amber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Perfect Circle</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>sigur rós</td>\n",
       "      <td>( )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>sigur rós</td>\n",
       "      <td>Olsen Olsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>sigur rós</td>\n",
       "      <td>Untitled #3 (samskeyti)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>the beatle</td>\n",
       "      <td>Blackbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>yes</td>\n",
       "      <td>And you and I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist                    track\n",
       "0      Ludovico Einaudi                 Divenire\n",
       "1      Ludovico Einaudi                Primavera\n",
       "2           .Hack//SIGN      Key of the Twilight\n",
       "3                   311                    Amber\n",
       "4      A Perfect Circle                     Blue\n",
       "...                 ...                      ...\n",
       "1237          sigur rós                      ( )\n",
       "1238          sigur rós              Olsen Olsen\n",
       "1239          sigur rós  Untitled #3 (samskeyti)\n",
       "1240         the beatle                Blackbird\n",
       "1241                yes            And you and I\n",
       "\n",
       "[1242 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(savefile) \\\n",
    "    .drop_duplicates() \\\n",
    "    .dropna() \\\n",
    "    .sort_values([\"artist\", \"track\"]) \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "df.to_csv('silver.csv', index=False)\n",
    "\n",
    "print(len(df))\n",
    "# tweak further to get to gold.csv\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Radiohead</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Nick Drake</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Simon and Garfunkel</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Simon &amp; Garfunkel</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Jim Croce</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>The Cure</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>The Beach Boys</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Sigur Rós</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Sigur Ros</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist  track\n",
       "374            Radiohead    167\n",
       "333           Nick Drake     53\n",
       "443          The Beatles     31\n",
       "409  Simon and Garfunkel     17\n",
       "408    Simon & Garfunkel     16\n",
       "231            Jim Croce     13\n",
       "452             The Cure     13\n",
       "442       The Beach Boys     13\n",
       "406            Sigur Rós     12\n",
       "405            Sigur Ros     12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('artist') \\\n",
    "    .count() \\\n",
    "    .reset_index() \\\n",
    "    .sort_values('track', ascending=False) \\\n",
    "    .head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df['artist']=='Unknown'].index)\n",
    "df = df.drop(df.loc[df['artist']=='unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>unknown</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Hallelujah</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>various works</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>The Boxer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>In My Life</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Bridge Over Troubled Water</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Dream A Little Dream Of Me</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Time After Time</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>The Sound of Silence</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Absolutely</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           track  artist\n",
       "1107                     unknown      10\n",
       "333                   Hallelujah       7\n",
       "1109               various works       6\n",
       "901                    The Boxer       5\n",
       "410                   In My Life       4\n",
       "128   Bridge Over Troubled Water       4\n",
       "229   Dream A Little Dream Of Me       4\n",
       "973              Time After Time       4\n",
       "930         The Sound of Silence       4\n",
       "28                    Absolutely       3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('track') \\\n",
    "    .count() \\\n",
    "    .reset_index() \\\n",
    "    .sort_values('artist', ascending=False) \\\n",
    "    .head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df['track']=='Unknown'].index)\n",
    "df = df.drop(df.loc[df['track']=='unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('silver.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into a Spotify playlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=os.getenv('SPOTIFY_CLIENT_ID'), \n",
    "                                                      client_secret=os.getenv('SPOTIFY_CLIENT_SECRET'),\n",
    "                                                      )\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check artists\n",
    "df = pd.read_csv(\"silver.csv\")\n",
    "df.drop_duplicates() \\\n",
    "    .dropna() \\\n",
    "    .sort_values([\"artist\", \"track\"])\n",
    "\n",
    "dedupe = {}\n",
    "fail_list = []\n",
    "\n",
    "for index, artist, title in df.itertuples():\n",
    "    if artist in dedupe:\n",
    "        continue\n",
    "    dedupe[artist]=1\n",
    "    query_str = 'artist:%s' % (artist)\n",
    "    artist_results = sp.search(q=query_str, type='artist', limit=3, offset=0, market='US')\n",
    "    artist_names = [artist['name'] for artist in artist_results['artists']['items']]\n",
    "    if artist_names:\n",
    "        if artist.lower() != artist_names[0].lower():\n",
    "            print(artist, artist_names)\n",
    "    else:\n",
    "        fail_list.append((artist, title))\n",
    "        print(\"not found:\", artist, \"-\", title)\n",
    "\n",
    "# then clean up manually as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracks\n",
    "\n",
    "df = pd.read_csv(\"silver.csv\")\n",
    "df.drop_duplicates() \\\n",
    "    .dropna() \\\n",
    "    .sort_values([\"artist\", \"track\"])\n",
    "\n",
    "dedupe = {}\n",
    "mylist = []\n",
    "fail_list = []\n",
    "artist_list, track_list, uri_list, album_list = [], [], [], []\n",
    "orig_artist, orig_track = [], []\n",
    "\n",
    "for index, artist, title in df.itertuples():\n",
    "    query_str = 'artist:%s track:%s' % (artist, title)\n",
    "    track_results = sp.search(q=query_str, type='track', limit=1, offset=0, market='US')\n",
    "    results = track_results['tracks']['items']\n",
    "    \n",
    "    if results:\n",
    "        r = results[0]\n",
    "        # failsafe to never put same track twice\n",
    "        if dedupe.get(r['id']):\n",
    "            continue\n",
    "        dedupe[r['id']]=True\n",
    "        if title.lower() != r['name'].lower():\n",
    "            print (\"%s|%s : %s|%s\" % (artist, title, r['artists'][0]['name'], r['name']))\n",
    "        uri_list.append(r['uri'])\n",
    "        artist_list.append(r['artists'][0]['name'])\n",
    "        track_list.append(r['name'])\n",
    "        album_list.append(r['album']['name'])\n",
    "        orig_artist.append(artist)\n",
    "        orig_track.append(title)\n",
    "#         print('  ',\n",
    "#               r['artists'][0]['name'],'|',\n",
    "#               r['name'], '|',\n",
    "#               r['album']['name'],'|',\n",
    "#               r['album']['release_date'],'|',\n",
    "#               r['popularity'])\n",
    "    else:\n",
    "        fail_list.append((artist, title))\n",
    "        print(\"not found:\", artist, \"-\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.DataFrame({'input_artist': orig_artist,\n",
    "                        'artist': artist_list,\n",
    "                        'input_track': orig_track,\n",
    "                        'track': track_list,\n",
    "                        'album': album_list,\n",
    "                        'uri': uri_list})\n",
    "gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 999):\n",
    "    display(gold_df.loc[gold_df['input_artist'].str.lower() != gold_df['artist'].str.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df2=gold_df.copy().reset_index(drop=True)\n",
    "gold_df2['input_track']=gold_df2['input_track'].str.lower()\n",
    "gold_df2['input_track']=gold_df2['input_track'].apply(lambda s: s.strip()[:10])\n",
    "\n",
    "gold_df2['track']=gold_df2['track'].str.lower()\n",
    "gold_df2['track']=gold_df2['track'].apply(lambda s: s.strip()[:10])\n",
    "\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", 999):\n",
    "    display(gold_df2.loc[gold_df2['input_track'] != gold_df2['track']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are songs that look like covers or otherwise not the expected response from spotify search \n",
    "# (which is a bit wonky, doesn't like quotes and such)\n",
    "\n",
    "bad_lookups = [\n",
    "#    25,134,155,160,200,209,422,445,446,557,737,744,755,759,760,761,762,781,785,790,814,815,842\n",
    "    21,51,61,63,83,145,212,317,322,439,449,575,759,784,\n",
    "]\n",
    "\n",
    "for i in bad_lookups:\n",
    "    print(gold_df.iloc[i])\n",
    "    \n",
    "# add manually, plus 'not found'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = gold_df.drop(\n",
    "    axis='index',\n",
    "    labels=bad_lookups)\n",
    "\n",
    "gold_df[['artist', 'track']].to_csv('gold.csv', index=False)\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", 999):\n",
    "    display(gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get playlist id\n",
    "# first create a playlist in UI to load songs\n",
    "playlists = sp.user_playlists(os.getenv('SPOTIFY_USERNAME'))\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        if playlist['name'] != 'Reddit Prettiest Songs':\n",
    "            continue\n",
    "        print(playlist['id'])\n",
    "        playlist_id = playlist['id']\n",
    "        print(\"%4d %s %s\" % (i + 1 + playlists['offset'], playlist['uri'],  playlist['name']))\n",
    "    if playlists['next']:\n",
    "        playlists = sp.next(playlists)\n",
    "    else:\n",
    "        playlists = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must follow an oauth workflow to write a playlist in Spotify\n",
    "# running this cell should request a spotify login and then redirect to an url\n",
    "# paste whole url with id into form to authenticate\n",
    "\n",
    "scope = \"playlist-modify-public\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=spotipy.SpotifyOAuth(scope=scope,\n",
    "                                                       client_id=os.getenv('SPOTIFY_CLIENT_ID'),\n",
    "                                                       client_secret=os.getenv('SPOTIFY_CLIENT_SECRET'),\n",
    "                                                       redirect_uri=\"https://druce.ai\"\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addlist = gold_df['uri'].to_list()\n",
    "# print (len(addlist))\n",
    "\n",
    "# while(addlist):\n",
    "#     sp.user_playlist_add_tracks(os.getenv('SPOTIFY_USERNAME'), \n",
    "#                                 playlist_id=playlist_id, \n",
    "#                                 tracks=addlist[-100:])\n",
    "#     addlist = addlist[:-100]\n",
    "#     print(\"added items, remaining \", len(addlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add the ones that weren't found for some reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can run again and add any new tracks, either because OpenAI is a bit random, or new replies in thread\n",
    "results = sp.user_playlist(os.getenv('SPOTIFY_USERNAME'), playlist_id,\n",
    "                                fields='tracks,next,name')\n",
    "tracks = results['tracks']\n",
    "\n",
    "playlist_dict_by_uri = {}\n",
    "playlist_dict_by_str = {}\n",
    "\n",
    "artist_list = []\n",
    "track_list = []\n",
    "uri_list = []\n",
    "popularity_list = []\n",
    "album_list=[]\n",
    "\n",
    "while True:\n",
    "    for track_item in tracks['items']:\n",
    "        track_dict = track_item['track']\n",
    "        track_str = track_dict['artists'][0]['name']  + ' | ' + track_dict['name'][:15]\n",
    "        uri = track_dict['uri']\n",
    "        if track_str in playlist_dict_by_str:\n",
    "            print(track_str)\n",
    "        playlist_dict_by_str[track_str] = uri\n",
    "        playlist_dict_by_uri[uri] = track_str\n",
    "        \n",
    "        uri_list.append(uri)\n",
    "        artist_list.append(track_dict['artists'][0]['name'])\n",
    "        track_list.append(track_dict['name'])\n",
    "        album_list.append(track_dict['album']['name'])\n",
    "        popularity_list.append(track_dict['popularity'])\n",
    "        \n",
    "    # check if there are more pages\n",
    "    if tracks['next']:\n",
    "        tracks = sp.next(tracks)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print (len(list(playlist_dict_by_str.keys())))\n",
    "print (len(list(playlist_dict_by_uri.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = pd.DataFrame({'artist': artist_list,\n",
    "                           'track': track_list,\n",
    "                           'album': album_list,\n",
    "                           'popularity': popularity_list,\n",
    "                           })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 9999):\n",
    "    display(playlist_df.sort_values('popularity'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dict_by_uri = {}\n",
    "gold_dict_by_str = {}\n",
    "addlist = []\n",
    "c = 0\n",
    "for i, artist, track, uri in gold_df[['artist', 'track', 'uri']].itertuples():\n",
    "    # print(artist, track, uri)\n",
    "    track_str = artist + ' | ' + track[:15]\n",
    "    if track_str not in playlist_dict_by_str:\n",
    "        addlist.append([artist, track, uri])\n",
    "        print(artist, track, uri)\n",
    "    gold_dict_by_uri[uri]=track_str\n",
    "    gold_dict_by_str['track_str']= uri\n",
    "#     if track_str not in playlist_dict_by_str:\n",
    "#         c += 1\n",
    "#         print (c, track_str)\n",
    "        \n",
    "print(len(gold_dict_by_str.items()))\n",
    "print(len(gold_dict_by_uri.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addlist = [['ABBA', 'One Of Us', 'spotify:track:6zgtBUEkAfilJ2YEOvNexR'],\n",
    " ['Gregorio Allegri',\n",
    "  'Miserere mei, Deus',\n",
    "  'spotify:track:6es7DmrhnDoKj5rsFvh3XU'],\n",
    " ['Amy Winehouse',\n",
    "  'Love Is A Losing Game',\n",
    "  'spotify:track:3uliGwmB52ZA7brgpZMzyH'],\n",
    " ['Barbara',\n",
    "  \"Ma plus belle histoire d'amour\",\n",
    "  'spotify:track:0qBVET4VkHsQAoboWlQ2pJ'],\n",
    " ['Ludwig van Beethoven',\n",
    "  'Symphony No. 5 in C Minor, Op. 67: I. Allegro con brio',\n",
    "  'spotify:track:2ygeBLTP9uu3OW3VTulD8N'],\n",
    " ['Benny Goodman', 'Sing, Sing, Sing', 'spotify:track:5L8ta4ECl5zeA6bGqY7G38'],\n",
    " ['Bill Withers', 'Lean on Me', 'spotify:track:3M8FzayQWtkvOhqMn2V4T2'],\n",
    " ['Billy Joel', 'Piano Man', 'spotify:track:70C4NyhjD5OZUMzvWZ3njJ'],\n",
    " ['Bob Dylan', 'Ballad of a Thin Man', 'spotify:track:0f5N14nB8xi0p3o4BlVvbx'],\n",
    " ['Bob Dylan', \"Blowin' in the Wind\", 'spotify:track:18GiV1BaXzPVYpp9rmOg0E'],\n",
    " ['Bob Dylan', 'Desolation Row', 'spotify:track:4n1ZGm3TxYmoYe1YR8cMus'],\n",
    " ['Bob Dylan', 'Duquesne Whistle', 'spotify:track:5kKW4bszhKSCYVPDO0sMbX'],\n",
    " ['Bob Dylan',\n",
    "  'Forever Young - Slow Version',\n",
    "  'spotify:track:4yWl0tnEanf3zmZzl9kbQn'],\n",
    " ['Bob Dylan', 'Gotta Serve Somebody', 'spotify:track:760420tYNmNjFgi8bWvbop'],\n",
    " ['Bob Dylan', 'Highway 61 Revisited', 'spotify:track:6os5B6xjuke9YfBKH3tu1e'],\n",
    " ['Bob Dylan',\n",
    "  'I Shall Be Released - Studio Outtake - 1971',\n",
    "  'spotify:track:5vyw005QQ42hrzrLxb3xEX'],\n",
    " ['Bob Dylan', 'I Want You', 'spotify:track:7tJQ4Ekp2vN3NlI3vJJW3v'],\n",
    " ['Bob Dylan', \"It Ain't Me Babe\", 'spotify:track:5nbNWAfT1S6V1vqj3snHxS'],\n",
    " ['Bob Dylan', 'Jokerman', 'spotify:track:6cuHkcRUqtQhtJ4sWCkd1q'],\n",
    " ['Bob Dylan',\n",
    "  \"Knockin' On Heaven's Door\",\n",
    "  'spotify:track:6HSXNV0b4M4cLJ7ljgVVeh'],\n",
    " ['Bob Dylan', 'Lay, Lady, Lay', 'spotify:track:4uYwlMp841PLJmj1gJJwIq'],\n",
    " ['Bob Dylan', 'Like a Rolling Stone', 'spotify:track:3AhXZa8sUQht0UEdBJgpGc'],\n",
    " ['Bob Dylan', 'Love Sick', 'spotify:track:3O1hpSOaJDW4SelgUG2XT3'],\n",
    " ['Bob Dylan', \"Maggie's Farm\", 'spotify:track:5rGD8FFgHw74cp3RPhucyg'],\n",
    " ['Bob Dylan',\n",
    "  'Make You Feel My Love',\n",
    "  'spotify:track:6rfGPGghQL7SJmZPXprXIc'],\n",
    " ['Bob Dylan',\n",
    "  'Mississippi - Version 2',\n",
    "  'spotify:track:6JWHNd8QMxTvojYkmZtKGI'],\n",
    " ['Bob Dylan', 'Mr. Tambourine Man', 'spotify:track:3RkQ3UwOyPqpIiIvGVewuU'],\n",
    " ['Bob Dylan', 'Murder Most Foul', 'spotify:track:1LfTvT9JPYuuZanwxLtZCr'],\n",
    " ['Bob Dylan', 'Not Dark Yet', 'spotify:track:1qbn6QrHG8XfnqVFKgNzKP'],\n",
    " ['Bob Dylan',\n",
    "  'Rainy Day Women #12 & 35',\n",
    "  'spotify:track:7BkAlVpGwXXl3sYNn5OoJ7'],\n",
    " ['Bob Dylan',\n",
    "  'Sad-Eyed Lady of the Lowlands',\n",
    "  'spotify:track:4jdtLLyEL7wY0TlCdMKhxq'],\n",
    " ['Bob Dylan', 'She Belongs to Me', 'spotify:track:2itBkHBUxGl4VfDj4HNyoD'],\n",
    " ['Bob Dylan',\n",
    "  'Stuck Inside of Mobile with the Memphis Blues Again',\n",
    "  'spotify:track:1NYTj6JEw3IOh4ggiBh82h'],\n",
    " ['Bob Dylan',\n",
    "  'Subterranean Homesick Blues',\n",
    "  'spotify:track:6k9DUKMJpWvu6eFG3O64Lg'],\n",
    " ['Bob Dylan', 'Tangled up in Blue', 'spotify:track:6Vcwr9tb3ZLO63F8DL8cqu'],\n",
    " ['Bob Dylan', 'Tempest', 'spotify:track:19scNzd4ogVsHrNWsms8Rg'],\n",
    " ['Bob Dylan',\n",
    "  \"The Times They Are A-Changin'\",\n",
    "  'spotify:track:52vA3CYKZqZVdQnzRrdZt6'],\n",
    " ['Bob Dylan',\n",
    "  'Things Have Changed - Single Version',\n",
    "  'spotify:track:5KOi77ameCimkAdw0DMNoy'],\n",
    " ['Bob Dylan',\n",
    "  'Thunder on the Mountain',\n",
    "  'spotify:track:4wo2eRp6aHcAlmhmfwiTAH'],\n",
    " ['Bob Dylan', 'Visions of Johanna', 'spotify:track:2rslQV48gNv3r9pPrQFPW1'],\n",
    " ['Brian Wilson', 'God Only Knows', 'spotify:track:2SznAUigFh6rMdGpcS5d7e'],\n",
    " ['Bright Eyes',\n",
    "  'First Day of My Life',\n",
    "  'spotify:track:0eBryM7ePQH3Klt3jz8xZd'],\n",
    " ['Crowded House',\n",
    "  'Don’t Dream It’s Over - Home Demo',\n",
    "  'spotify:track:0fiSpF9mvRFQWy0ca64d1g'],\n",
    " ['Léo Delibes', 'Flower Duet', 'spotify:track:5K8jqeLAxZIqHR6e5w5so1'],\n",
    " ['Dire Straits', 'Brothers In Arms', 'spotify:track:6XYBbVpu455ZdGWZNRLGbG'],\n",
    " ['Don McLean',\n",
    "  'Vincent (Starry, Starry Night)',\n",
    "  'spotify:track:2YDyH60Vro33KkDtNZCXIk'],\n",
    " ['Ed Sheeran', 'Photograph', 'spotify:track:41xNsY82OWtWbIfnRMK2ky'],\n",
    " ['Elvis Presley',\n",
    "  'Can’t Help Falling in Love - Acoustic Cover',\n",
    "  'spotify:track:0ghQkNDYLSl4GsqfkjTjWx'],\n",
    " ['Enya', 'Amarantine', 'spotify:track:0VmzazQQ0Mo1vJldr5NxTW'],\n",
    " ['Evan Rachel Wood', 'If I Fell', 'spotify:track:0gd3hRBQAEAw096YOcUrmR'],\n",
    " ['Fleetwood Mac', 'Rhiannon', 'spotify:track:05oETzWbd4SI33qK2gbJfR'],\n",
    " ['George Harrison',\n",
    "  'All Things Must Pass - 2014 Remaster',\n",
    "  'spotify:track:16OwZQuzMqnwn3FZsCBZly'],\n",
    " ['George Harrison',\n",
    "  'Apple Scruffs - 2014 Remaster',\n",
    "  'spotify:track:2K7WhpfZX3TCCMiwebp0W7'],\n",
    " ['George Harrison',\n",
    "  'Art of Dying - 2014 Remaster',\n",
    "  'spotify:track:6Jod7qrtYBhU3HcUmKk4hX'],\n",
    " ['George Harrison',\n",
    "  'Awaiting on You All - 2014 Remaster',\n",
    "  'spotify:track:0b65WkrBrg2qOkzQeDtQ9d'],\n",
    " ['George Harrison',\n",
    "  'Ballad of Sir Frankie Crisp (Let It Roll) - 2014 Remaster',\n",
    "  'spotify:track:0FWeRrB8T5R6maHbWQw4Kk'],\n",
    " ['George Harrison',\n",
    "  'Behind That Locked Door',\n",
    "  'spotify:track:2VVbLn8nMcWJzjcL1tZsUr'],\n",
    " ['George Harrison',\n",
    "  'Beware of Darkness - 2014 Remaster',\n",
    "  'spotify:track:606MCyZFMBlc52Ojnn1nvU'],\n",
    " ['George Harrison',\n",
    "  'Give Me Love (Give Me Peace on Earth)',\n",
    "  'spotify:track:71fXxvXqo1zxWDtBmjoEVk'],\n",
    " ['George Harrison',\n",
    "  'Hear Me Lord - 2014 Remaster',\n",
    "  'spotify:track:3kopbNyRj10XO1actGZexP'],\n",
    " ['George Harrison',\n",
    "  'I Dig Love - 2014 Remaster',\n",
    "  'spotify:track:42yK1Wy62c7malKSRwy0Qk'],\n",
    " ['George Harrison',\n",
    "  'I Remember Jeep - 2014 Remaster',\n",
    "  'spotify:track:058AE5M3ifbCh8VWOV7903'],\n",
    " ['George Harrison',\n",
    "  \"It's Johnny's Birthday - 2014 Remaster\",\n",
    "  'spotify:track:6Cv05rcW8HWwCC6wyEp1fC'],\n",
    " ['George Harrison',\n",
    "  'Let It Down - 2014 Remaster',\n",
    "  'spotify:track:5FFruMKbVg8AhwHnX4xBov'],\n",
    " ['George Harrison',\n",
    "  'My Sweet Lord - 2014 Remaster',\n",
    "  'spotify:track:6vE90mi4yKsQGY3YD2OOv1'],\n",
    " ['George Harrison',\n",
    "  'Out of the Blue - 2014 Remaster',\n",
    "  'spotify:track:1KHMyFaGvwVQ7ax4yjq4BZ'],\n",
    " ['George Harrison',\n",
    "  'Plug Me In - 2014 Remaster',\n",
    "  'spotify:track:0tyk2xHVjBd3nk16cGktTG'],\n",
    " ['George Harrison',\n",
    "  'Run of the Mill - 2014 Remaster',\n",
    "  'spotify:track:4uSlUBg3NVOA77E7wwKFTO'],\n",
    " ['George Harrison',\n",
    "  'Thanks for the Pepperoni - 2014 Remaster',\n",
    "  'spotify:track:3smkwfPqFsTmwfnBztMXaM'],\n",
    " ['George Harrison',\n",
    "  'The Inner Light (Alternative Take) - Instrumental',\n",
    "  'spotify:track:7gWPnvhaBFMlQsTBWEGcSC'],\n",
    " ['George Harrison',\n",
    "  'Wah-Wah - 2014 Remaster',\n",
    "  'spotify:track:5j3aqkMO2fl0s5eaSuVnQ8'],\n",
    " ['George Harrison',\n",
    "  'What Is Life - 2014 Remaster',\n",
    "  'spotify:track:44fw7RulJyj7dGIi9qR86N'],\n",
    " ['George Harrison',\n",
    "  'While My Guitar Gently Weeps - Live At Madison Square Garden; 2009 Remaster',\n",
    "  'spotify:track:4Egi6XuC0rbLlXfqmQeuFa'],\n",
    " ['Glenn Miller', 'In the Mood', 'spotify:track:1xsY8IFXUrxeet1Fcmk4oC'],\n",
    " ['Hans Zimmer', 'Cornfield Chase', 'spotify:track:6pWgRkpqVfxnj3WuIcJ7WP'],\n",
    " ['Hans Zimmer',\n",
    "  'Day One (Interstellar Theme)',\n",
    "  'spotify:track:4WmB04GBqS4xPMYN9dHgBw'],\n",
    " [\"Israel Kamakawiwo'ole\",\n",
    "  'Maui Medley',\n",
    "  'spotify:track:6TSJ3L9pBQsYIlCD5pk7ju'],\n",
    " ['James Taylor',\n",
    "  'You’ve Got a Friend',\n",
    "  'spotify:track:3nK4hWsTEr7fVXziI5bTmh'],\n",
    " ['Jay Ungar', 'Ashoken Farewell', 'spotify:track:2s6pqLeVialgt5l5TTSeas'],\n",
    " ['Jeff Buckley',\n",
    "  'If You Knew - Live at Sin-é, New York, NY - July/August 1993',\n",
    "  'spotify:track:1nd2JEHXbUuQFDiQzCBpsv'],\n",
    " ['Jimi Hendrix', 'One Rainy Wish', 'spotify:track:5Zyv0v4rPcrXjkaeImuodv'],\n",
    " ['Jimi Hendrix',\n",
    "  'Spanish Castle Magic',\n",
    "  'spotify:track:2KFE98Iw0X23sf4vJYcbLH'],\n",
    " ['Jimi Hendrix',\n",
    "  'Wait Until Tomorrow',\n",
    "  'spotify:track:2YtVzmZzew1ILUdNueyWd7'],\n",
    " ['John Lennon',\n",
    "  'Imagine - Remastered 2010',\n",
    "  'spotify:track:7pKfPomDEeI4TPT6EOYjn9'],\n",
    " ['John Mayer', 'Queen of California', 'spotify:track:0CETmgFGt8Ne8vLnaLcduU'],\n",
    " ['Johnny Cash',\n",
    "  'I Walk The Line - Single Version',\n",
    "  'spotify:track:1TKPfF2fvn6gVLVfp3iG4j'],\n",
    " ['Joni Mitchell',\n",
    "  'Mitchell: Urge for Going (Instrumental Arrangement of the B-Side Track of the Joni Mitchell Single \"You Turn Me on I\\'m a Radio\")',\n",
    "  'spotify:track:1I1u9aTdxxQ7SDLgBB3V7b'],\n",
    " ['Kanye West', 'Come to Life', 'spotify:track:5xvXeuxISyXJDRbZZf4uzd'],\n",
    " ['Leonard Cohen', 'Chelsea Hotel #2', 'spotify:track:4krhCfJg0znykZoyjeMXRe'],\n",
    " ['Leonard Cohen', 'Dear Heather', 'spotify:track:3MTKMphPprAcBFG1uIhzPZ'],\n",
    " ['Leonard Cohen',\n",
    "  \"Death of a Ladies' Man\",\n",
    "  'spotify:track:5wrylUGwZugelovhryPYg2'],\n",
    " ['Leonard Cohen', 'The Future', 'spotify:track:5l8lYrnPEM1ln3J4XaTcy5'],\n",
    " ['Leonard Cohen',\n",
    "  'You Want It Darker',\n",
    "  'spotify:track:5zb7npjQqoJ7Kcpq4yD9qn'],\n",
    " ['Lingers.On', 'In Lingerie', 'spotify:track:6FH3kGlJbFVJDCG9RcERf7'],\n",
    " ['Louis Armstrong',\n",
    "  'La vie en rose - Single Version',\n",
    "  'spotify:track:3yYfoYGVpriV4fG9L1ogsD'],\n",
    " ['The Lovecats', 'The Lovecats', 'spotify:track:7iJUiiTfnuY5cTIeEBnqHr'],\n",
    " ['Ludovico Einaudi', 'Primavera', 'spotify:track:4BMHp3DkI8VLsuB9Kr0pzu'],\n",
    " ['Mazzy Star', 'Flowers In December', 'spotify:track:0G6Ws8Gbdt0S7pZeuYmkmm'],\n",
    " ['Metallica',\n",
    "  'Fade To Black (Remastered)',\n",
    "  'spotify:track:0dqGfCMAGyDgpUAgLNOjWd'],\n",
    " ['Wolfgang Amadeus Mozart',\n",
    "  'Requiem in D Minor, K. 626: III. Sequenz No. 6, Lacrimosa dies illa',\n",
    "  'spotify:track:4bvzJZXpkI3bkjxMCWOSu1'],\n",
    " ['My Chemical Romance',\n",
    "  'The Light Behind Your Eyes',\n",
    "  'spotify:track:3HyDpKAuR3e4l6QB7hSB2l'],\n",
    " ['Paul McCartney',\n",
    "  'Here Today - Remixed 2015',\n",
    "  'spotify:track:0QtnwXDziZN1K55fXuLN6q'],\n",
    " ['Paul McCartney',\n",
    "  'I’ll Follow The Sun - Live At Amoeba 2007',\n",
    "  'spotify:track:3xT59EeQdq0TPGtOlXXI8t'],\n",
    " ['Puscifer', 'The Humbling River', 'spotify:track:69GE6yPZZldvqtgBHrKXxg'],\n",
    " ['Ray LaMontagne',\n",
    "  'Such A Simple Thing',\n",
    "  'spotify:track:4PuUa8e5s7P3Zv1IdCGIsa'],\n",
    " ['Ray Manzarek',\n",
    "  'Riders on the Storm',\n",
    "  'spotify:track:3FvYcTXO2QtDY7kZQHku2d'],\n",
    " ['Red Hot Chili Peppers', 'Dosed', 'spotify:track:1iFIZUVDBCCkWe705FLXto'],\n",
    " ['Sky Cries Mary',\n",
    "  \"Don't Forget The Sky\",\n",
    "  'spotify:track:4sVpjCJRClVetRrdxVBolP'],\n",
    " ['Stevie Nicks', 'Landslide', 'spotify:track:5fprEY6WEN1wvFXkgfb22C'],\n",
    " ['Stevie Wonder', 'Isn’t She Lovely', 'spotify:track:6wGlAaMfyhKdEPr2zycAnN'],\n",
    " ['Taylor Swift',\n",
    "  'Fearless (Taylor’s Version)',\n",
    "  'spotify:track:77sMIMlNaSURUAXq5coCxE'],\n",
    " ['Taylor Swift',\n",
    "  'the lakes - bonus track',\n",
    "  'spotify:track:0eFQWVz0qIxDOvhLpZ40P7'],\n",
    " ['The Band',\n",
    "  'When I Paint My Masterpiece - Remastered',\n",
    "  'spotify:track:76WChUuOPeIK027IeUgr0l'],\n",
    " ['The Beach Boys',\n",
    "  \"I Just Wasn't Made For These Times - Mono\",\n",
    "  'spotify:track:4CuO8TINNqM3D7aUdNQ3zG'],\n",
    " ['The Beach Boys',\n",
    "  \"Let's Go Away For A While - Mono\",\n",
    "  'spotify:track:3GsgJI1aBrvUtqX8f3MhKT'],\n",
    " ['The Beatles',\n",
    "  \"Don't Let Me Down - Naked Version / Remastered 2013\",\n",
    "  'spotify:track:5BhMoGrz5KzG2fA5uzHjZ1'],\n",
    " ['The Beatles',\n",
    "  'Love Me Do - Remastered 2009',\n",
    "  'spotify:track:3VbGCXWRiouAq8VyMYN2MI'],\n",
    " ['The Chemical Brothers',\n",
    "  'The Boxer',\n",
    "  'spotify:track:1EUeDFq2zNP784GPaRs9aH'],\n",
    " ['The Cure',\n",
    "  'A Night like This - 2006 Remaster',\n",
    "  'spotify:track:7cKCz7gG84i1XLvDeM3ByT'],\n",
    " ['The Cure',\n",
    "  'Disintegration - 2010 Remaster',\n",
    "  'spotify:track:0zY8t5dC1KQXcPUKByWMJM'],\n",
    " ['The Cure',\n",
    "  'From the Edge of the Deep Green Sea',\n",
    "  'spotify:track:2vwBL9RVyr0vA4Og5VH0i3'],\n",
    " ['The Cure',\n",
    "  'In Between Days - 2006 Remaster',\n",
    "  'spotify:track:07CyrZF9eVd02zzIse7tZA'],\n",
    " ['The Cure', 'A Letter to Elise', 'spotify:track:4DdXOLc1VMAY34ourCn1Xa'],\n",
    " ['The Cure',\n",
    "  'Lullaby - 2010 Remaster',\n",
    "  'spotify:track:4d4oXk7O2lEhZ83ivV93li'],\n",
    " ['The Cure', 'Underneath The Stars', 'spotify:track:0PKVjYlKw7z3IvKAoxrYTR'],\n",
    " ['The Eagles', 'The Desperadoes', 'spotify:track:10ppF835WJMYI5v65gFLZ3'],\n",
    " ['The Helio Sequence',\n",
    "  'Keep Your Eyes Ahead',\n",
    "  'spotify:track:3yatRBsGMJ7wMoUIgDBzzo'],\n",
    " ['The Moldy Peaches',\n",
    "  'Anyone Else But You',\n",
    "  'spotify:track:2pKi1lRvXNASy7ybeQIDTy'],\n",
    " ['The Strokes', 'Someday', 'spotify:track:7hm4HTk9encxT0LYC0J6oI'],\n",
    " ['Traditional',\n",
    "  'Scarborough Fair (Arr. Parkin)',\n",
    "  'spotify:track:4wlNPczIullwvmwb4x0ltz'],\n",
    " ['Van Morrison',\n",
    "  'Madame George - 1999 Remaster',\n",
    "  'spotify:track:1N4MKISvC1ddfRCRQDXDd2'],\n",
    " ['Various Artists',\n",
    "  'The Girl From Ipanema',\n",
    "  'spotify:track:0JgH7g0kwsIs1THEVqhlUS'],\n",
    " ['Víg Mihály',\n",
    "  'Öreg - From \"Werckmeister Harmóniák\"',\n",
    "  'spotify:track:63wMgkXQuomlkW4an4O9b4'],\n",
    " ['Willie Nelson', 'Crazy', 'spotify:track:0xqtcLB45iKNfHroi5y1em']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(addlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addlist2 = [a[2] for a in addlist]\n",
    "\n",
    "print (len(addlist2), 'items')\n",
    "\n",
    "while(addlist2):\n",
    "    sp.user_playlist_add_tracks(os.getenv('SPOTIFY_USERNAME'), \n",
    "                                playlist_id=playlist_id, \n",
    "                                tracks=addlist2[-100:])\n",
    "    addlist2 = addlist2[:-100]\n",
    "    print(\"added items, remaining \", len(addlist2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
